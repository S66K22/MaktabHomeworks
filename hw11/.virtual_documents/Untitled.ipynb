


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report






df = pd.read_csv('diabetes.csv')
df.head(5).T


df.info()


df.describe()





missing_info = {}
missing_columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for column in missing_columns:
    zero_count = (df[column] == 0).sum()
    missing_percentage = (zero_count / df[column].shape[0]) * 100
    info_dict = {}
    info_dict['missing_count'] = zero_count
    info_dict['missing_percentage'] = missing_percentage
    missing_info[column] = info_dict

print("missing data count and percentage:\n")
missing_df = pd.DataFrame(missing_info)
missing_df





for column in missing_columns:
    df[column] = df[column].replace(to_replace=0, value=np.nan)





df.isnull().sum()









df_strategy_A = df.copy()

imputers_strategy_A = {}
for column in missing_columns:
    imputers_strategy_A[column] = SimpleImputer(strategy='mean')

imputers_strategy_A


for column, imputer in imputers_strategy_A.items():
    df_strategy_A[[column]] = imputer.fit_transform(df_strategy_A[[column]])


df_strategy_A.isnull().sum()


print(f"mean of Glucose before imputation: {imputers_strategy_A['Glucose'].statistics_}")
print(f"mean of Glucose before imputation: {df[['Glucose']].mean()}")
print(f"mean of Glucose after imputation: {df_strategy_A[['Glucose']].mean()}")








df_strategy_B = df.copy()

imputers_strategy_B = {}
for column in missing_columns:
    imputers_strategy_B[column] = {'Outcome_0': SimpleImputer(strategy='mean'), 'Outcome_1': SimpleImputer(strategy='mean')}

imputers_strategy_B


outcome_0_mask = df_strategy_B['Outcome'] == 0
outcome_1_mask = df_strategy_B['Outcome'] == 1

for col in missing_columns:   
    # Impute for Outcome == 0
    df_strategy_B.loc[outcome_0_mask, col] = imputers_strategy_B[col]['Outcome_0']\
        .fit_transform(df_strategy_B.loc[outcome_0_mask, [col]])
    
    # Impute for Outcome == 1
    df_strategy_B.loc[outcome_1_mask, col] = imputers_strategy_B[col]['Outcome_1']\
        .fit_transform(df_strategy_B.loc[outcome_1_mask, [col]])


print(f"mean of Glucose for Outcome 0 before imputation: {imputers_strategy_B['Glucose']['Outcome_0'].statistics_}")
print(f"mean of Glucose for Outcome 1 before imputation: {imputers_strategy_B['Glucose']['Outcome_1'].statistics_}")
print(f"mean of Glucose after imputation: {df_strategy_B.loc[outcome_0_mask, ['Glucose']].mean()}")
print(f"mean of Glucose after imputation: {df_strategy_B.loc[outcome_1_mask, ['Glucose']].mean()}")





df_strategy_C = df.copy()

strategy_C_imputers = {}
for column in missing_columns:
    strategy_C_imputers[column] = KNNImputer(n_neighbors=5)

strategy_C_imputers


for column, imputer in strategy_C_imputers.items():
    df_strategy_C[[column]] = imputer.fit_transform(df_strategy_C[[column]])


df_strategy_C.isnull().sum()











df_strategy_C_cat = df_strategy_C.copy()

df_strategy_C_cat['Glucose_cat'] = \
    pd.cut(df_strategy_C_cat['Glucose'], bins=[0, 100, 125, np.inf], labels=['Normal', 'Prediabetes', 'Diabetic'])


Glucose_cat_freq = (
    df_strategy_C_cat
    .groupby("Outcome")["Glucose_cat"]
    .value_counts(normalize=True)
    .unstack(level=0)
)

# Ensure consistent category order
Glucose_cat_freq = Glucose_cat_freq.sort_index()

# Plot grouped bar chart
Glucose_cat_freq.plot(kind="bar")

plt.ylabel("Proportion within outcome")
plt.xlabel("Glucose Category")
plt.title("Normalized Glucose Category Frequency by Outcome")
plt.legend(title="Outcome")
plt.tight_layout()
plt.show()





df_strategy_C_cat['BMI_cat'] = \
    pd.cut(df_strategy_C_cat['BMI'], bins=[0, 18.5, 25, 30, np.inf], labels=['Underweight', 'Normal', 'Overweight', 'Obese'])


BMI_cat_freq = (
    df_strategy_C_cat
    .groupby("Outcome")["BMI_cat"]
    .value_counts(normalize=True)
    .unstack(level=0)
)

# Ensure consistent category order
BMI_cat_freq = BMI_cat_freq.sort_index()

# Plot grouped bar chart
BMI_cat_freq.plot(kind="bar")

plt.ylabel("Proportion within outcome")
plt.xlabel("BMI Category")
plt.title("Normalized BMI Category Frequency by Outcome")
plt.legend(title="Outcome")
plt.tight_layout()
plt.show()





df_strategy_C_cat['Age_cat'] = \
    pd.cut(df_strategy_C_cat['Age'], bins=[21, 30, 45, 60, np.inf], labels=['Young', 'Middle_Aged', 'Senior', 'Elderly'])


Age_cat_freq = (
    df_strategy_C_cat
    .groupby("Outcome")["Age_cat"]
    .value_counts(normalize=True)
    .unstack(level=0)
)

# Ensure consistent category order
Age_cat_freq = Age_cat_freq.sort_index()

# Plot grouped bar chart
Age_cat_freq.plot(kind="bar")

plt.ylabel("Proportion within outcome")
plt.xlabel("Age Category")
plt.title("Normalized Age Category Frequency by Outcome")
plt.legend(title="Outcome")
plt.tight_layout()
plt.show()





df_strategy_C_cat['Insulin_to_Glucose_Ratio'] = df_strategy_C_cat['Insulin'] / df_strategy_C_cat['Glucose']


corr = df_strategy_C.corr(numeric_only=True)


corr['Outcome'].sort_values(ascending=False)








df_strategy_C_cat['BloodPressure_cat'] = \
    pd.cut(df_strategy_C_cat['BloodPressure'], bins=[0, 80, 90, np.inf], labels=['Low', 'Normal', 'High'])


BloodPressure_cat_freq = (
    df_strategy_C_cat
    .groupby("Outcome")["BloodPressure_cat"]
    .value_counts(normalize=True)
    .unstack(level=0)
)

# Ensure consistent category order
BloodPressure_cat_freq = BloodPressure_cat_freq.sort_index()

# Plot grouped bar chart
BloodPressure_cat_freq.plot(kind="bar")

plt.ylabel("Proportion within outcome")
plt.xlabel("BloodPressure Category")
plt.title("Normalized BloodPressure Category Frequency by Outcome")
plt.legend(title="Outcome")
plt.tight_layout()
plt.show()








df_strategy_C_cat.head(1).T


df_strategy_C_cat = df_strategy_C_cat.drop(columns=['Glucose', 'BMI', 'Age', 'BloodPressure'])
df_strategy_C_cat.head(1).T


df_strategy_C_cat = df_strategy_C_cat[['Pregnancies', 'SkinThickness', 'Insulin', 'DiabetesPedigreeFunction', 'Glucose_cat', 'BMI_cat', 'Age_cat',
       'Insulin_to_Glucose_Ratio', 'BloodPressure_cat', 'Outcome']]

df_strategy_C_cat.head(1).T


X = df_strategy_C_cat.drop(columns=['Outcome'])
y = df_strategy_C_cat['Outcome']

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    stratify=y,
    test_size=0.2,
    random_state=42
)


X_train.head()


y_train.head()





numeric_cols = X_train.select_dtypes(include=['number']).columns.tolist()
categorical_cols = X_train.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()

print(f"numeric_cols: {numeric_cols}")
print(f"categorical_cols: {categorical_cols}")


ohe_y = OneHotEncoder(
    handle_unknown='ignore'
)

# Fit on training labels only
y_train_ohe = ohe_y.fit_transform(y_train.to_numpy().reshape(-1, 1))

# Transform test labels
y_test_ohe = ohe_y.transform(y_test.to_numpy().reshape(-1, 1))


preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ]
)






svm_pipeline = Pipeline(
    steps=[
        ('preprocessor', preprocessor),
        ('model', SVC(probability=True, random_state=42))
    ]
)


param_grid = [
    # Linear SVM
    {
        'model__kernel': ['linear'],
        'model__C': [0.01, 0.1, 1, 10]
    },

    # Polynomial SVM
    {
        'model__kernel': ['poly'],
        'model__C': [0.1, 1, 10],
        'model__degree': [2, 3, 4],
        'model__gamma': ['scale', 'auto']
    },

    # RBF SVM
    {
        'model__kernel': ['rbf'],
        'model__C': [0.1, 1, 10],
        'model__gamma': ['scale', 'auto']
    }
]

scoring = {
    'accuracy': 'accuracy',
    'recall': 'recall',          # for binary classification
    'f1': 'f1',
    'precision': 'precision'
}



grid_search = GridSearchCV(
    estimator=svm_pipeline,
    param_grid=param_grid,
    scoring=scoring,
    refit='f1',          # model selection metric
    cv=5,
    n_jobs=-1,
    verbose=2,
    return_train_score=True
)






grid_search.fit(X_train, y_train)


# Convert results to a DataFrame
results_df = pd.DataFrame(grid_search.cv_results_)

# Display relevant columns
columns_of_interest = [
    'params', 
    'mean_test_accuracy', 'mean_test_precision', 'mean_test_recall', 'mean_test_f1',
    'std_test_accuracy', 'std_test_precision', 'std_test_recall', 'std_test_f1'
]
print("Full Grid Search Results:")
print(results_df[columns_of_interest].sort_values(by='mean_test_f1', ascending=False))

# Print the best model
print("\nBest Model Based on F1 Score:")
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)


# Optional: separate reports per kernel
kernels = ['linear', 'poly', 'rbf']
for kernel in kernels:
    kernel_results = results_df[results_df['param_model__kernel'] == kernel]
    if not kernel_results.empty:
        best_idx = kernel_results['mean_test_f1'].idxmax()
        print(f"\nBest {kernel.upper()} SVM:")
        print("Params:", kernel_results.loc[best_idx, 'params'])
        print("Accuracy:", kernel_results.loc[best_idx, 'mean_test_accuracy'])
        print("Precision:", kernel_results.loc[best_idx, 'mean_test_precision'])
        print("Recall:", kernel_results.loc[best_idx, 'mean_test_recall'])
        print("F1 Score:", kernel_results.loc[best_idx, 'mean_test_f1'])


# Function to plot confusion matrix
def plot_conf_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(title)
    plt.show()

# Loop through kernels and plot confusion matrices
kernels = ['linear', 'poly', 'rbf']

for kernel in kernels:
    # Get the best parameters for this kernel
    kernel_results = pd.DataFrame(grid_search.cv_results_)
    kernel_results = kernel_results[kernel_results['param_model__kernel'] == kernel]
    if not kernel_results.empty:
        best_idx = kernel_results['mean_test_f1'].idxmax()
        best_params = kernel_results.loc[best_idx, 'params']
        
        # Update pipeline with best params
        best_pipeline = svm_pipeline.set_params(**best_params)
        best_pipeline.fit(X_train, y_train)
        
        # Predict on test set
        y_pred = best_pipeline.predict(X_test)
        
        # Plot confusion matrix
        plot_conf_matrix(y_test, y_pred, title=f'Confusion Matrix - {kernel.upper()} SVM')





def fit(df):
    X = df.drop(columns=['Outcome'])
    y = df['Outcome']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        stratify=y,
        test_size=0.2,
        random_state=42
    )

    numeric_cols = X_train.select_dtypes(include=['number']).columns.tolist()
    categorical_cols = X_train.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
    
    print(f"numeric_cols: {numeric_cols}")
    print(f"categorical_cols: {categorical_cols}")
    
    ohe_y = OneHotEncoder(
        handle_unknown='ignore'
    )

    # Fit on training labels only
    y_train_ohe = ohe_y.fit_transform(y_train.to_numpy().reshape(-1, 1))
    
    # Transform test labels
    y_test_ohe = ohe_y.transform(y_test.to_numpy().reshape(-1, 1))
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_cols),
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
        ]
    )
    
    svm_pipeline = Pipeline(
        steps=[
            ('preprocessor', preprocessor),
            ('model', SVC(probability=True, random_state=42))
        ]
    )


    param_grid = [
        # Linear SVM
        {
            'model__kernel': ['linear'],
            'model__C': [0.01, 0.1, 1, 10]
        },
    
        # Polynomial SVM
        {
            'model__kernel': ['poly'],
            'model__C': [0.1, 1, 10],
            'model__degree': [2, 3, 4],
            'model__gamma': ['scale', 'auto']
        },
    
        # RBF SVM
        {
            'model__kernel': ['rbf'],
            'model__C': [0.1, 1, 10],
            'model__gamma': ['scale', 'auto']
        }
    ]

    scoring = {
        'accuracy': 'accuracy',
        'recall': 'recall',          # for binary classification
        'f1': 'f1',
        'precision': 'precision'
    }
    
    grid_search = GridSearchCV(
        estimator=svm_pipeline,
        param_grid=param_grid,
        scoring=scoring,
        refit='f1',          # model selection metric
        cv=5,
        n_jobs=-1,
        verbose=2,
        return_train_score=True
    )

    grid_search.fit(X_train, y_train)
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(grid_search.cv_results_)
    
    # Display relevant columns
    columns_of_interest = [
        'params', 
        'mean_test_accuracy', 'mean_test_precision', 'mean_test_recall', 'mean_test_f1',
        'std_test_accuracy', 'std_test_precision', 'std_test_recall', 'std_test_f1'
    ]
    print("Full Grid Search Results:")
    print(results_df[columns_of_interest].sort_values(by='mean_test_f1', ascending=False))
    
    # Print the best model
    print("\nBest Model Based on F1 Score:")
    print("Best Parameters:", grid_search.best_params_)
    print("Best F1 Score:", grid_search.best_score_)
    
    # Optional: separate reports per kernel
    kernels = ['linear', 'poly', 'rbf']
    for kernel in kernels:
        kernel_results = results_df[results_df['param_model__kernel'] == kernel]
        if not kernel_results.empty:
            best_idx = kernel_results['mean_test_f1'].idxmax()
            print(f"\nBest {kernel.upper()} SVM:")
            print("Params:", kernel_results.loc[best_idx, 'params'])
            print("Accuracy:", kernel_results.loc[best_idx, 'mean_test_accuracy'])
            print("Precision:", kernel_results.loc[best_idx, 'mean_test_precision'])
            print("Recall:", kernel_results.loc[best_idx, 'mean_test_recall'])
            print("F1 Score:", kernel_results.loc[best_idx, 'mean_test_f1'])
    
    # Loop through kernels and plot confusion matrices
    kernels = ['linear', 'poly', 'rbf']

    for kernel in kernels:
        # Get the best parameters for this kernel
        kernel_results = pd.DataFrame(grid_search.cv_results_)
        kernel_results = kernel_results[kernel_results['param_model__kernel'] == kernel]
        if not kernel_results.empty:
            best_idx = kernel_results['mean_test_f1'].idxmax()
            best_params = kernel_results.loc[best_idx, 'params']
            
            # Update pipeline with best params
            best_pipeline = svm_pipeline.set_params(**best_params)
            best_pipeline.fit(X_train, y_train)
            
            # Predict on test set
            y_pred = best_pipeline.predict(X_test)
            print(f"classification_report for {kernel}: {classification_report(y_test, y_pred)}")

            # Plot confusion matrix
            plot_conf_matrix(y_test, y_pred, title=f'Confusion Matrix - {kernel.upper()} SVM')


fit(df_strategy_A)


fit(df_strategy_B)


fit(df_strategy_C)






